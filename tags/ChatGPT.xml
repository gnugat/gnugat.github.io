<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Loïc Faugeron]]></title>
    <link href="/feed/atom.xml" rel="self"/>
    <link href="/"/>
    <updated>2023-03-24T16:36:48+00:00</updated>
    <id>http://gnugat.github.com</id>
            <author>
            <name><![CDATA[Loïc Faugeron]]></name>            <email><![CDATA[faugeron.loic@gmail.com]]></email>        </author>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[ChatGPT: fluff or not? Academic Prompt Engineering]]></title>
            <link href="/2023/03/24/chat-gpt-academic-prompt-engineering.html"/>
            <updated>2023-03-24T00:00:00+00:00</updated>
            <id>/2023/03/24/chat-gpt-academic-prompt-engineering.html</id>
            <content type="html"><![CDATA[<p>Now that a couple of months have passed since its over hyped launch,
surely <a href="https://openai.com/blog/chatgpt/">ChatGPT</a> has found some
use cases where it could be of any actual use. Or is it all fluff? Let's find out.</p>

<p>In my quest to find a use for ChatGPT in my day to day developer activity,
I've stumbled upon this online course website:
<a href="https://learnprompting.org/]">Learn Prompting</a>,
an initiative lead by <a href="https://trigaten.github.io/">Sander Schulhoff</a>,
with contributions from <a href="https://towardsai.net/">Towards AI</a>.</p>

<p>Granted, this doesn't bring me anywhere close to my goal...
Yet, this is in stark contrast to all the resources that I've found so far,
which are usually "hey I tried this hack and it worked", with no explanations
on why.</p>

<p>Let me walk you through the different Prompt Engineering techniques,
and why they work, with some academic backing, so we can learn a thing or two.</p>

<blockquote>
  <p><strong>Note</strong>: It was extremely tempting to describe how ChatGPT works,
  but I didn't want the explanations to detract from the focus of the article
  (which is academic backed prompt engineering).
  I recommend these short articles for a detailed explanations:
  * <a href="https://iq.opengenus.org/gpt-3-5-model/">GPT 3.5 model</a>
  * <a href="https://gist.github.com/veekaybee/6f8885e9906aa9c5408ebe5c7e870698">Everything I (Vicki Boykis) understand about ChatGPT</a></p>
</blockquote>

<h2 id="x-shot-prompting"><a href="https://learnprompting.org/docs/basics/standard_prompt">X-Shot Prompting</a></h2>

<p>X-Shot prompting allows Large Language Models to improve their accuracy,
on previously unseen data, without the need to update their training parameters,
by including examples in the prompt:</p>

<pre><code>Extract the brand, product name and format from this item "Magnum White Chocolate Ice Cream 8 x 110 ml":
* brand: Magnum
* product name: White Chocolate Ice Cream
* format: 8 x 110 ml

Extract the brand, product name and format from this item "Birds Eye Garden Peas, 375g (Frozen)":
* brand: Birds Eye
* product name: Garden Peas
* format: 375g

Extract the brand, product name and format from this item "PG tips 160 Original Tea Bags":
* brand: PG tips
* product name: Original Tea Bags
* format: 160

Extract the brand, product name and format from this item "233g, Golden Eggs Chocolate Egg, Galaxy":
</code></pre>

<p>There's a distinction between Few-Shot, One-Shot and Zero-Shot prompting
(referring to how many examples are included in the prompt).</p>

<p>Isn't Zero-Shot prompting just... Prompting? Well X-Shot isn't just about
having examples in the prompt, it's mainly about the capability of the model
to perform better on new data it wasn't trained on, so we're going to see
that "Zero-Shot" term used in conjunction with other techniques.</p>

<blockquote>
  <p>See also, <a href="https://www.allabtai.com/">Kris - All About AI</a>'s article:
  <a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/">X-Shot Prompting</a></p>
</blockquote>

<h2 id="chain-of-thought-prompting"><a href="https://learnprompting.org/docs/intermediate/chain_of_thought">Chain of Thought Prompting</a></h2>

<p>Few-Shot Chain of Thought prompting allows Large Language Models
to perform better on logic based tasks (such as solving arithmetic,
commonsense, and symbolic problems) by including in the examples
the reasoning steps:</p>

<pre><code>Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.
Each can has 3 tennis balls. How many tennis balls does he have now?

A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls.
5 + 6 = 11. The answer is 11.

Q: The cafeteria had 23 apples. If they use 20 to make lunch and bought 6 more,
how many apples do they have?
</code></pre>

<p>Zero-Shot Chain of Thought prompting can also be used to get better results
for these tasks, by including in the prompt a request to detail the reasoning
steps:</p>

<pre><code>A juggler can juggle 16 balls. Half of the balls are golf balls,
and half of the golf balls are blue. How many blue golf balls are there?
Let's think step by step.
</code></pre>

<p>More specifically, ending the prompt with <code>Let's think step by step</code> proved
to provide the best results
(claim backed in the paper <a href="https://arxiv.org/abs/2201.11903">CoT Prompting Elicits Reasoning in LLM</a>).</p>

<h2 id="generated-knowledge-prompting"><a href="https://learnprompting.org/docs/intermediate/generated_knowledge">Generated Knowledge prompting</a></h2>

<p>Generated Knowledge prompting allows Large Language Models to perform better
on commonsense reasoning by having a first prompt requesting the generation
of knowledge on a topic, and then incorporating the output in a second prompt
that requests top perform the related commonsense task.</p>

<p>Here's the first prompt asking for knowledge generation:</p>

<pre><code>Write 5 facts about test driven development
</code></pre>

<p>Then the second prompt which incorporates the output for the first prompt:</p>

<pre><code>Here are 5 facts about TDD:
1. Test-driven development (TDD) is a software development process that emphasizes the creation of automated tests before any code is written. In TDD, developers write a failing test case first, then write code to pass the test, and then refactor the code to improve it.
2. TDD helps to ensure that the code is working correctly by testing it at every step of the development process. By creating tests first, developers can also ensure that their code meets the requirements and specifications of the project.
3. TDD can be used with a variety of programming languages and frameworks, and it is often used in agile development methodologies. It can also be used in combination with other testing techniques, such as behavior-driven development (BDD) and acceptance test-driven development (ATDD).
4. TDD can result in improved code quality, as developers are forced to think more deeply about the design of their code and the potential edge cases that their code may encounter. TDD can also result in faster development times, as bugs are caught early in the development process and can be fixed before they cause more significant issues.
5. TDD is not a silver bullet solution for software development and may not be suitable for all projects or teams. It can require additional time and effort upfront to write tests and ensure that they are passing, and it may require a cultural shift in the development team to fully adopt the TDD methodology.

With TDD, can I first write code that fails, then write a test and finally refactor the code to make the test pass?
</code></pre>

<blockquote>
  <p><em>Note: I've seen this as also being referred to as Chain Prompting.</em></p>
</blockquote>

<h2 id="takeways">Takeways</h2>

<p>The following prompt engineering techniques are proven by studies to improve
the output quality of Large Language Models:</p>

<ul>
<li>X-Shot: include examples in the prompt</li>
<li>Chain of Thought: end the prompt with <code>Let's think step by step</code></li>
<li>Knowlegde Generated:

<ul>
<li>first ask to generate facts on a topic</li>
<li>then ask a question on the topic, including the previously generated facts</li>
</ul></li>
</ul>

<p>All in all, while I haven't found a practical use case for ChatGPT in my day to day developer activity,
it still seems worth exploring its potential for generating content. The quest continues.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[ChatGPT: fluff or not? Prompt Engineering]]></title>
            <link href="/2023/03/01/chat-gpt.html"/>
            <updated>2023-03-01T00:00:00+00:00</updated>
            <id>/2023/03/01/chat-gpt.html</id>
            <content type="html"><![CDATA[<p>Now that a couple of months have passed since its over hyped launch,
surely <a href="https://openai.com/blog/chatgpt/">ChatGPT</a> has found some
use cases where it could be of any actual use. Or is it all fluff? Let's find out.</p>

<p>In my quest to find a use for ChatGPT in my day to day developer activity,
I've stumbled upon this video:
<a href="https://www.youtube.com/watch?v=Xs7wieu-35k]">ChatGPT Prompt Engineering: How to Write a Story</a>,
by <a href="https://www.allabtai.com/">Kris - All About AI</a>).</p>

<p>Granted, story writing is a bit irrelevant for what I'm looking for.
Yet the way the messages sent to ChatGPT (aka "prompts") were crafted,
proved quite interesting!</p>

<p>Let me walk you through it,
with some added references so we can learn a thing or two.</p>

<h2 id="1st-prompt%3A-%22you%27re-an-expert%22">1st prompt: "You're an expert"</h2>

<p>After opening a new conversation,
the First Prompt (or user message) sent to ChatGPT is used to prime it:</p>

<pre><code>You are a {Genre} author.
Your task is to write {Genre} stories in a vivid and intriguing language.
Answer with "..." if you acknowledge.
Don't write anything yet.

Genre = Sci-Fi
</code></pre>

<p>This is a variation of the <code>You are [job], you have been [doing thing] for 20 years</code> prompt,
which helps ChatGPT narrow down the context that it's going to use to generate its replies.</p>

<blockquote>
  <p>Reference: "Give ChatGPT an identity" section from
  <a href="https://wgmimedia.com/how-to-use-chatgpt-advanced-prompt-engineering/">How To Use ChatGPT: Advanced Prompt Engineering</a></p>
</blockquote>

<p>Interestingly, it uses a placeholder (<code>{Genre}</code>) and sets its value (<code>Genre = Sci-Fi</code>).</p>

<p>It also makes sure that ChatGPT doesn't generate any reply.</p>

<p>Could this be because ChatGPT will base its next replies
on any text it will have already generated in the conversation?</p>

<h2 id="2nd-prompt%3A-%22templates-within-templates%22">2nd prompt: "Templates within Templates"</h2>

<p>The Second Prompt is used to specify more context for chatGPT:</p>

<pre><code>Title: [Insert story title here]
Setting: [Insert setting details here, including time period, location, and any relevant background information]
Protagonist: [Insert protagonist's name, age, and occupation, as well as a brief description of their personality and motivations]
Fill out the template above for a {Genre} story
Genre = Sci-Fi
</code></pre>

<p>The brilliance of this one is that it uses a second kind of placeholder (<code>[Insert story title here]</code>),
one that is intended for ChatGPT to replace (<code>Fill out template above</code>).</p>

<p>If ChatGPT is indeed going to base its next reply
on whatever it has already generated earlier in the conversation,
then having it repeat the instructions with the added details is simply genius.</p>

<p>The list format might also not be trivial,
as I've seen claims that usage of colons (<code>Title: [insert story title here]</code>)
is supposed to help ChatGPT be more specific in its replies too.</p>

<blockquote>
  <p>Reference: "Prompt 2" chapter from
  <a href="https://youtu.be/HGDxu3kPErs">Advanced ChatGPT Prompt Tutorial</a></p>
</blockquote>

<h2 id="3rd-%26-4th-prompts%3A-%22now%2C-do-your-job%22">3rd &amp; 4th prompts: "Now, do your job"</h2>

<p>While the First and Second prompts were about setting the context,
the Third and Fourth ones are finally the calls to action.</p>

<p>Here's the Third Prompt:</p>

<pre><code>Build a story outlines from the factors above:
</code></pre>

<p>ChatGPT is going to generate an ordered list based on the context previously given.</p>

<p>Then the Fourth Prompt:</p>

<pre><code>Great, now create story chapters from the outlines above:
</code></pre>

<p>ChatGPT is going to reuse its reply for the Third Prompt, and expand on it.</p>

<p>I'm taking note of the use of the word <code>Great</code>,
could its purpose be to give some positive feedback to ChatGPT?</p>

<p>Another thing worth mentioning is the use of the word <code>now</code>,
which I see a lot from prompt engineers,
and I'm not sure if it's delibarate to improve ChatGPT replies.</p>

<p>But most importantly,
I'm wondering how <code>from the factors above</code> is intepreted by ChatGPT:
is it going to consider every messages sent in the current conversation,
or is it going to focus on the immediately prior message.</p>

<p>I've personally got a feeling that ChatGPT will focus mainly on its own
replies from the conversation.</p>

<p>The usage of a final colon <code>:</code> is especially noteworthy,
I'd be curious to know if this is another hack to help ChatGPT write more focused replies.</p>

<h2 id="5th-prompt%3A-%22use-given-style%22">5th prompt: "Use given style"</h2>

<p>The Fifth Prompt is yet another call to action:</p>

<pre><code>Write Chapter 1 in depth and in great detail, in a intriguing writing style:
</code></pre>

<p>It asks ChatGPT to reuse its previous reply and expand on it,
but this time only a section of it by referencing the chapter number
(<code>Write Chapter 1</code>)!</p>

<p>The rest of the prompt is a variation of
<code>Write a [length] [content type] on [topic] in the style of [style]</code>.</p>

<p>Specifying some constraints such as these helps ChatGPT avoid irrelevant output.</p>

<blockquote>
  <p>Reference: "Be specific, descriptive and as detailed as possible about
  the desired context, outcome, length, format, style, etc " section from
  <a href="https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api">Best practices for prompt engineering with OpenAI API</a></p>
</blockquote>

<h2 id="5th-prompt-bis%3A-prompt-editing%21">5th prompt (bis): Prompt Editing!</h2>

<p>In my opinion, the most important piece of advice from that video
comes in play when writing the second to tenth chapters:</p>

<pre><code>Write Chapter 2 in depth and in great detail, in a intriguing writing style:
</code></pre>

<p>Instead of copying the prompt, pasting it in the input message box,
changing the chapter number and then sending it as the Sixth Prompt,
the advice we're given is to <strong>edit the Fifth Prompt</strong> (through ChatGPT's UI),
change the number and submit it!</p>

<p>ChatGPT's UI will still allow you to check the previous versions of the prompt,
as well as their generated replies, so you don't lose anything here.</p>

<p>But this ties in with the idea that ChatGPT performs better with its immediately prior message,
than asking it to expand on a reply it wrote 10 messages earlier.</p>

<h2 id="takeways">Takeways</h2>

<p>While the purpose of the video was to write a Sci-Fi story,
it helped learn a lot of Prompt Engineering techniques
(the art of crafting messages that will improve ChatGPT replies).</p>

<p>The First Prompt needs to prime ChatGPT for the targeted domain,
and make sure that it doesn't reply anything:</p>

<pre><code>You're [JOB].
You have been [DOING JOB] for 20 years.
Your task is now to [TASK].
Answer with "..." if you acknowledge.
Don't write anything yet.
</code></pre>

<p>It seems to me that ChatGPT bases its reply on its own immediately prior message,
so the Second Prompt needs to make ChatGPT repeat it in its reply,
to set up the context for the Third Prompt's reply.</p>

<p>The usage of colons (<code>:</code>) helps ChatGPT to be more specific in its replies,
and it's possible to use placeholders that are going to be replaced
with generated content in ChatGPT reply:</p>

<pre><code>Title: [Insert title]
Setting: [Insert setting details here]
Fill out the template above for a Sci-Fi story
</code></pre>

<p>If the prompt is intended to be copy pasted and used in different scenarios,
it's possible to use placeholders that act as variables,
and to which the value is set further down the prompt:</p>

<pre><code>You are a {Genre} author.
Your task is to write {Genre} stories

Genre = Sci-Fi
</code></pre>

<p>The Third Prompt is going to be a call to action,
that's going to use the Second Prompt's reply for context.</p>

<pre><code>Now, write [length] [content type] on [topic] in the style of [style], using [context] from above:
</code></pre>

<p>While we're on the topic of length it's very important to bear in mind that
<em>shared between the prompt you write and the reply it generates,
<strong>ChatGPT can only handle 4000 tokens</strong></em>, which is approximately 3000 words
(when it uses the <a href="https://platform.openai.com/docs/models/gpt-3">text-davinci-003 model</a>).</p>

<p>So for example, if your prompt contains 3000 tokens,
it only leaves ChatGPT with a 1000 token left for its reply!</p>

<blockquote>
  <p>Reference: "Important: Prompt Size Matters" chapter from
  <a href="https://www.youtube.com/watch?v=EYjG6i53-xk">This Will Make You Better than 99% ChatGPT Users</a></p>
</blockquote>

<p>The Fourth Prompt is going to be a call to action,
that's going to use the Third Prompt's reply for context, and so on.</p>

<p>If for some reason the Fifth Prompt needs to use the Third Prompt's reply for context,
then we should instead edit directly the Third Prompt, make the required changes, and submit them.</p>

<p>All in all, while I haven't found a practical use case for ChatGPT in my day to day developer activity,
it still seems worth exploring its potential for generating content. The quest continues.</p>
]]></content>
        </entry>
    </feed>